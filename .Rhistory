perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 1
perm_diffs <- numeric(n_perm)
set.seed(444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 1
perm_diffs <- numeric(n_perm)
set.seed(4444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 1
perm_diffs <- numeric(n_perm)
set.seed(44444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 1
perm_diffs <- numeric(n_perm)
set.seed(444444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 3
perm_diffs <- numeric(n_perm)
set.seed(444444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 3
perm_diffs <- numeric(n_perm)
set.seed(444444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
# --- Large run (500,000 permutations) ---
n_perm <- 500000
perm_diffs <- numeric(n_perm)
set.seed(444444)  # reproducibility for this run too
for (i in 1:n_perm){
shuffled <- sample(data)
perm_group_A <- shuffled[1:n_A]
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)]
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 3
perm_diffs <- numeric(n_perm)
set.seed(444444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
# --- Large run (500,000 permutations) ---
n_perm <- 500000
perm_diffs <- numeric(n_perm)
set.seed(444444)  # reproducibility for this run too
for (i in 1:n_perm){
shuffled <- sample(data)
perm_group_A <- shuffled[1:n_A]
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)]
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 3
perm_diffs <- numeric(n_perm)
set.seed(444444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
# --- Large run (500,000 permutations) ---
n_perm <- 5000
perm_diffs <- numeric(n_perm)
set.seed(444444)  # reproducibility for this run too
for (i in 1:n_perm){
shuffled <- sample(data)
perm_group_A <- shuffled[1:n_A]
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)]
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
p_value
group_A <- c(14, 18, 11, 13, 18, 17, 21, 9, 16, 17, 14, 15)
group_B <- c(12, 12, 14, 13, 6, 18, 14, 16, 10, 7, 15, 10)
data <- c(group_A, group_B)
n_A <- length(group_A)
n_B <- length(group_B)
obs_diff <- mean(group_A) - mean(group_B)
n_perm <- 3
perm_diffs <- numeric(n_perm)
set.seed(444444)
for (i in 1:n_perm){
shuffled <- sample(data) # randomly reorders all the values
perm_group_A <- shuffled[1:n_A] # take the first 12 values from shuffled
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)] # take the next 12 values from shuffled
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
# You’ll have n_perm simulated differences in means stored in perm_diffs.
# These make up the null distribution
# Then you compare your observed difference to this distribution to see how extreme it is.
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
perm_diffs
obs_diff
p_value
# --- Large run (500,000 permutations) ---
n_perm <- 5000
perm_diffs <- numeric(n_perm)
set.seed(444444)  # reproducibility for this run too
for (i in 1:n_perm){
shuffled <- sample(data)
perm_group_A <- shuffled[1:n_A]
perm_group_B <- shuffled[(n_A+1):(n_A+n_B)]
perm_diffs[i] <- mean(perm_group_A) - mean(perm_group_B)
}
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
p_value
hist(perm_diffs, breaks = 50, col = "lightblue",
main = "Permutation Test: Difference in Means",
xlab = "Difference in Means")
abline(v = obs_diff, col = "red", lwd = 2, lty = 2)
legend("topright", legend = paste("Observed Diff =", round(obs_diff, 3)),
col = "red", lty = 2, lwd = 2)
install.packages("readxl")
library(readxl)
powd
pwd
unique(df$Group)
data <- read_excel("~/Desktop/experimental_design/FunctionalReach.xlsx")
unique(df$Group)
data <- read_excel("~/Desktop/experimental_design/FunctionalReach.xlsx")
unique(data$Group)
length(unique(data$Group))
table(data$Group)
length(unique(data$Group))
sum(table(data$Group))
grand_mean <- mean(data$Response)
SST <- sum((data$Response - grand_mean)^2)
SST
table(data$Group)
group_means <- tapply(data$Response, data$Group, mean)
group_means
group_means <- tapply(data$Response, data$Group, mean)
group_sizes <- table(data$Group)
SSB <- sum(group_sizes * (group_means - grand_mean)^2)
SSB
print(SST-SSB)
length(unique(data$Group))
sum(table(data$Group))
MSB <- SSB / (length(unique(data$Group)) - 1)
MSW <- (SST-SSB) / (sum(table(data$Group)) - length(unique(data$Group)))
MSB
MSW
F <- MSB / MSW
F
group_means <- tapply(data$Response, data$Group, mean)
group_means
predicted <- group_means[data$Group]
# Residual = observed - predicted
res <- data$Response - predicted
# Now make Q-Q plot of residuals
qqnorm(res, main = "Normal Q-Q Plot of Residuals")
qqline(res, col = "red")
res
group_means
library(dplyr)
group_means <- data |>
group_by(Group) |>
summarize(mean_response = mean(Response))
group_means
group_means <- data |>
group_by(Group)
group_means
n=185
print(n=185)
print(group_means, n=185)
group_means <- data |>
group_by(Group) |>
summarize(mean_response = mean(Response))
group_means
data_with_pred <- data |>
left_join(group_means, by = "Group")
data_with_pred <- data_with_pred |>
mutate(residual = Response - mean_response)
data_with_pred
qqnorm(data_with_pred$residual, main = "Normal Q-Q Plot of Residuals")
qqline(data_with_pred$residual, col = "red")
model <- aov(Response ~ Group, data = data)
plot(model)
group_sds
group_sds <- tapply(data$Response, data$Group, sd)
group_sds
group_sds <- tapply(data$Response, data$Group, sd)
data <- read_excel("~/Desktop/experimental_design/FunctionalReach.xlsx")
unique(data$Group)
length(unique(data$Group))
sum(table(data$Group))
# Sum of squares
grand_mean <- mean(data$Response)
SST <- sum((data$Response - grand_mean)^2)
SST
group_means <- tapply(data$Response, data$Group, mean)
group_sizes <- table(data$Group)
SSB <- sum(group_sizes * (group_means - grand_mean)^2)
SSB
print(SST-SSB)
MSB <- SSB / (length(unique(data$Group)) - 1)
MSW <- (SST-SSB) / (sum(table(data$Group)) - length(unique(data$Group)))
MSB
MSW
F <- MSB / MSW
F
# Checking assumptions
model <- aov(Response ~ Group, data = data)
plot(model)
group_sds <- tapply(data$Response, data$Group, sd)
group_sds
data <- read_excel("~/Desktop/experimental_design/FunctionalReach.xlsx")
unique(data$Group)
length(unique(data$Group))
sum(table(data$Group))
# Sum of squares
grand_mean <- mean(data$Response)
SST <- sum((data$Response - grand_mean)^2)
SST
group_means <- tapply(data$Response, data$Group, mean)
group_sizes <- table(data$Group)
SSB <- sum(group_sizes * (group_means - grand_mean)^2)
SSB
print(SST-SSB)
MSB <- SSB / (length(unique(data$Group)) - 1)
MSW <- (SST-SSB) / (sum(table(data$Group)) - length(unique(data$Group)))
MSB
MSW
F <- MSB / MSW
F
# Checking assumptions
model <- aov(Response ~ Group, data = data)
plot(model, which=2)
group_sds <- tapply(data$Response, data$Group, sd)
group_sds
max(group_sds)
typeof(group_sds)
print(max(group_sds) / min(group_sds))
model <- aov(Response ~ Group, data = data)
summary(model)
fanbase <- read_excel("~/Desktop/FanBase.xlsx")
fanbase <- read_excel("~/Desktop/FanBase.xls")
fanbase <- read_excel("~/Desktop/FanBase.xls")
fanbase <- read_excel("~/Desktop/experimental_design/FanBase.xls")
fanbase <- read_excel("~/Desktop/experimental_design/FanBase.xls")
library(tibble)
data <- tribble(
~Cuba, ~Nicaragua, ~Costa_Rica,
5.36,    25.66,      1.51,
23.88,     2.01,      2.32,
9.70,     1.06,     14.20,
11.44,     1.02,      8.75,
0.54,     5.49,      4.75,
3.64,     2.28,        NA,
15.36,       NA,        NA,
1.33,     ,        NA
)
data <- tribble(
~Cuba, ~Nicaragua, ~Costa_Rica,
5.36,    25.66,      1.51,
23.88,     2.01,      2.32,
9.70,     1.06,     14.20,
11.44,     1.02,      8.75,
0.54,     5.49,      4.75,
3.64,     2.28,        NA,
15.36,       NA,        NA,
1.33,     NA ,        NA
)
data
data_long <- pivot_longer(
data,
cols = everything(),
names_to = "Group",
values_to = "Response",
values_drop_na = TRUE
)
library(tidyr)
data_long <- pivot_longer(
data,
cols = everything(),
names_to = "Group",
values_to = "Response",
values_drop_na = TRUE
)
data_long
kruskal.test(Response ~ Group, data = data_long)
library(agricolae)
install.packages("agricolae")
library(agricolae)
design <- design.bib(trt = c("a", "b", "c", "d"), k = 3, r = 3, seed = 42)
design
library(readxl)
BIBDs1 <- read_excel("C:/Users/bethd/OneDrive/Desktop/BIBDs1.xlsx")
setwd(~/Desktop/experimental_design)
setwd("~/Desktop/experimental_design")
Cycle <- as.factor(Cycle)
library(readxl)
Fabric <- read_excel("Fabric.xlsx")
View(Fabric)
Cycle <- as.factor(Cycle)
Fabric$Cycle <- as.factor(Cycle)
Cycle <- as.factor(Fabric$Cycle)
Cycle <- as.factor(Fabric$Cycle)
Operator <- as.factor(Fabric$Operator)
Temp <- as.factor(Fabric$Temp)
df <- data.frame(Fabric$Cloth, Cycle, Operator, Temp)
model <- aov(Cloth ~ Cycle * Operator * Temp, data=df)
df
df <- data.frame(Fabric$Cloth, Cycle, Operator, Temp)
df
df <- data.frame(Cloth, Cycle, Operator, Temp)
Cycle <- as.factor(Fabric$Cycle)
Operator <- as.factor(Fabric$Operator)
Temp <- as.factor(Fabric$Temp)
df <- data.frame(Fabric$Cloth, Cycle, Operator, Temp)
model <- aov(Cloth ~ Cycle * Operator * Temp, data=df)
df
Fabric
df <- data.frame(Cloth, Cycle, Operator, Temp)
Cloth <- Fabric$Cloth
Cycle <- as.factor(Fabric$Cycle)
Operator <- as.factor(Fabric$Operator)
Temp <- as.factor(Fabric$Temp)
df <- data.frame(Cloth, Cycle, Operator, Temp)
model <- aov(Cloth ~ Cycle * Operator * Temp, data=df)
summary(model)
Cloth <- Fabric$Cloth
Cycle <- as.factor(Fabric$Cycle)
Operator <- as.factor(Fabric$Operator)
Temp <- as.factor(Fabric$Temp)
df <- data.frame(Cloth, Cycle, Operator, Temp)
df
model <- aov(Cloth ~ Cycle * Operator * Temp, data=df)
summary(model)
df
cell_means <- aggregate(Cloth ~ Cycle * Operator * Temp, data=df, FUN = mean)
cell_means
read_excel("Test.xlsx")
read_excel("Tests.xlsx")
data <- read_excel("Tests.xlsx")
read_excel("Tests.xlsx")
m1 <- aov (Result ~ Children + Test, data=data)
summary(m1)
TukeyHSD(m1, conf.level = 0.95)
plot(TukeyHSD(m1, conf.level = 0.95))
summary(m1)
data <- read_excel("Tests.xlsx")
data
m1
m1 <- aov(Result ~ Children + as.Factor(Test), data=data)
raw_data <- read_excel("Tests.xlsx")
raw_data$Test <- as.factor(raw_data$Test)
m1 <- aov(Result ~ Children + Test, data=data)
summary(m1)
summary(m1)
summary(m1)
summary(m1)
summary(m1)
summary(m1)
m1 <- aov(Result ~ Children + Test, data=data)
raw_data <- read_excel("Tests.xlsx")
raw_data$Test <- as.factor(raw_data$Test)
m1 <- aov(Result ~ Children + Test, data=raw_data)
summary(m1)
